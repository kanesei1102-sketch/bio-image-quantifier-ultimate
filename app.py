"""
Bio-Image Quantifier: Ultimate Hybrid Edition
OpenCVé«˜é€Ÿå‡¦ç† + scikit-imageç§‘å­¦çš„åŽ³å¯†æ€§ + è¦åˆ¶é©åˆæ€§

Features:
- Hybrid Engine: OpenCV (HSVè‰²æŠ½å‡º) + scikit-image (ç‰©ç†é‡è§£æž)
- Regulatory Compliance: FDA 21 CFR Part 11, PMDA GCTP
- Cloud Optimized: Streamlit Cloudå®Œå…¨å¯¾å¿œ
"""

import streamlit as st
import numpy as np
import pandas as pd
import cv2
from skimage import io as skio, filters, morphology, measure, segmentation, color, exposure
from skimage.feature import peak_local_max
from scipy import ndimage as ndi
import matplotlib
matplotlib.use('Agg')  # ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒå¯¾å¿œ
import matplotlib.pyplot as plt
import seaborn as sns
import datetime
import uuid
import hashlib
import io
import gc
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple, Optional, Literal, Union

# ============================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ============================================
st.set_page_config(
    page_title="Bio-Image Quantifier Ultimate",
    page_icon="ðŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
# ============================================
@dataclass(frozen=True)
class SystemConfig:
    """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¨­å®šç®¡ç†"""
    VERSION: str = "4.0.0-Ultimate-Hybrid"
    COMPLIANCE_STANDARDS: List[str] = None
    
    def __post_init__(self):
        object.__setattr__(self, 'COMPLIANCE_STANDARDS', [
            "FDA 21 CFR Part 11",
            "PMDA GCTP",
            "ISO 13485"
        ])
    
    # OpenCV HSVè‰²å®šç¾©
    COLOR_MAP_HSV: Dict[str, Dict[str, np.ndarray]] = None
    
    def get_color_map(self):
        if self.COLOR_MAP_HSV is None:
            return {
                "Brown (DAB)": {"lower": np.array([10, 50, 20]), "upper": np.array([30, 255, 255])},
                "Green (GFP)": {"lower": np.array([35, 50, 50]), "upper": np.array([85, 255, 255])},
                "Red (RFP)": {"lower": np.array([0, 50, 50]), "upper": np.array([10, 255, 255])},
                "Blue (DAPI)": {"lower": np.array([100, 50, 50]), "upper": np.array([140, 255, 255])}
            }
        return self.COLOR_MAP_HSV

CONFIG = SystemConfig()

# ============================================
# ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆALCOA+æº–æ‹ ï¼‰
# ============================================
@dataclass
class AnalysisParameters:
    """è§£æžãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç›£æŸ»è¨¼è·¡å¯¾å¿œï¼‰"""
    # åŸºæœ¬æƒ…å ±
    mode: str
    stain_type: str = "IF"
    
    # å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    scale_um_per_px: float = 1.5267
    min_area: int = 30
    max_area: int = 500
    
    # OpenCVç³»ï¼ˆHSVè‰²æŠ½å‡ºï¼‰
    target_color: Optional[str] = None
    sensitivity: int = 20
    brightness_min: int = 60
    
    # scikit-imageç³»ï¼ˆç‰©ç†é‡è§£æžï¼‰
    threshold_method: str = "otsu"
    rolling_ball_radius: int = 50
    use_watershed: bool = True
    
    # å…±å±€åœ¨ãƒ»è·é›¢è§£æžç”¨
    target_color_b: Optional[str] = None
    sensitivity_b: int = 20
    brightness_b: int = 60
    
    # ROIæ­£è¦åŒ–
    use_roi_normalization: bool = False
    roi_color: Optional[str] = None
    roi_sensitivity: int = 20
    roi_brightness: int = 40
    
    # ç›£æŸ»è¨¼è·¡
    operator_id: str = "System"
    analysis_purpose: str = "Research"
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    def get_hash(self) -> str:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€æ„ãƒãƒƒã‚·ãƒ¥ï¼ˆæ”¹ã–ã‚“æ¤œçŸ¥ï¼‰"""
        import json
        param_str = json.dumps(self.to_dict(), sort_keys=True)
        return hashlib.sha256(param_str.encode()).hexdigest()[:16]

@dataclass
class AnalysisResult:
    """è§£æžçµæžœï¼ˆå®Œå…¨ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ï¼‰"""
    # è­˜åˆ¥æƒ…å ±
    analysis_id: str
    session_id: str
    timestamp_utc: str
    software_version: str
    
    # ç”»åƒæƒ…å ±
    image_name: str
    image_hash: str
    image_size_px: Tuple[int, int]
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parameters: AnalysisParameters
    
    # ä¸»è¦çµæžœ
    primary_value: float
    primary_unit: str
    
    # è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    cell_count: int = 0
    total_area_px: int = 0
    total_area_mm2: float = 0.0
    mean_intensity: float = 0.0
    std_intensity: float = 0.0
    
    # æ‹¡å¼µãƒ¡ãƒˆãƒªã‚¯ã‚¹
    extended_metrics: Dict[str, Union[float, int, str]] = None
    
    # å“è³ªç®¡ç†
    qc_flags: List[str] = None
    processing_time_sec: float = 0.0
    
    def __post_init__(self):
        if self.extended_metrics is None:
            self.extended_metrics = {}
        if self.qc_flags is None:
            self.qc_flags = []
    
    def to_dict(self) -> Dict:
        result = asdict(self)
        result['parameters'] = self.parameters.to_dict()
        return result

# ============================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
# ============================================
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    defaults = {
        'session_id': f"SID-{datetime.datetime.now(datetime.timezone.utc).strftime('%Y%m%d')}-{str(uuid.uuid4())[:8]}",
        'analysis_history': [],
        'uploader_key': str(uuid.uuid4()),
        'operator_name': "Anonymous",
        'project_name': "Research Project"
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ============================================
# ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç”»åƒå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
# ============================================
class HybridImageEngine:
    """OpenCV + scikit-imageãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    @staticmethod
    def load_image_universal(file_bytes: bytes) -> Tuple[np.ndarray, np.ndarray, str]:
        """
        æ±Žç”¨ç”»åƒèª­ã¿è¾¼ã¿
        Returns:
            (float_image [0-1], uint8_image [0-255], image_hash)
        """
        # ç”»åƒãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        img_hash = hashlib.sha256(file_bytes).hexdigest()[:16]
        
        # scikit-imageã§èª­ã¿è¾¼ã¿ï¼ˆãƒ“ãƒƒãƒˆæ·±åº¦ä¿æŒï¼‰
        img_raw = skio.imread(io.BytesIO(file_bytes))
        
        # float32æ­£è¦åŒ–
        if img_raw.dtype == np.uint8:
            img_float = img_raw.astype(np.float32) / 255.0
        elif img_raw.dtype == np.uint16:
            img_float = img_raw.astype(np.float32) / 65535.0
        else:
            img_float = img_raw.astype(np.float32)
            if img_float.max() > 1.0:
                img_float = img_float / img_float.max()
        
        # RGBå¤‰æ›
        if len(img_float.shape) == 2:
            img_float = color.gray2rgb(img_float)
        elif img_float.shape[2] == 4:
            img_float = color.rgba2rgb(img_float)
        
        # uint8å¤‰æ›
        img_uint8 = (img_float * 255).astype(np.uint8)
        
        return img_float, img_uint8, img_hash
    
    # ============================================
    # OpenCVç³»ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆé«˜é€Ÿè‰²æŠ½å‡ºï¼‰
    # ============================================
    @staticmethod
    def get_hsv_mask(img_uint8: np.ndarray, color_name: str, sensitivity: int, brightness_min: int) -> np.ndarray:
        """HSVè‰²ç©ºé–“ãƒžã‚¹ã‚¯ç”Ÿæˆï¼ˆOpenCVé«˜é€Ÿç‰ˆï¼‰"""
        hsv = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2HSV)
        color_map = CONFIG.get_color_map()
        
        if color_name == "Red (RFP)":
            # èµ¤è‰²ç‰¹æ®Šå‡¦ç†ï¼ˆHSVè‰²ç›¸ç’°ã®0Â°ã¨180Â°ï¼‰
            lower1 = np.array([0, 30, brightness_min])
            upper1 = np.array([10 + sensitivity//2, 255, 255])
            lower2 = np.array([170 - sensitivity//2, 30, brightness_min])
            upper2 = np.array([180, 255, 255])
            mask1 = cv2.inRange(hsv, lower1, upper1)
            mask2 = cv2.inRange(hsv, lower2, upper2)
            return cv2.bitwise_or(mask1, mask2)
        else:
            config = color_map.get(color_name, color_map["Blue (DAPI)"])
            lower = np.clip(config["lower"] - sensitivity, 0, 255)
            upper = np.clip(config["upper"] + sensitivity, 0, 255)
            lower[2] = max(lower[2], brightness_min)
            return cv2.inRange(hsv, lower, upper)
    
    @staticmethod
    def get_tissue_mask(img_uint8: np.ndarray, color_name: str, sensitivity: int, brightness_min: int) -> np.ndarray:
        """çµ„ç¹”é ˜åŸŸãƒžã‚¹ã‚¯ï¼ˆç©´åŸ‹ã‚å‡¦ç†ï¼‰"""
        mask = HybridImageEngine.get_hsv_mask(img_uint8, color_name, sensitivity, brightness_min)
        kernel = np.ones((15, 15), np.uint8)
        mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        contours, _ = cv2.findContours(mask_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        valid_tissue = [c for c in contours if cv2.contourArea(c) > 500]
        
        mask_filled = np.zeros_like(mask)
        cv2.drawContours(mask_filled, valid_tissue, -1, 255, thickness=cv2.FILLED)
        return mask_filled
    
    # ============================================
    # scikit-imageç³»ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆç§‘å­¦çš„åŽ³å¯†æ€§ï¼‰
    # ============================================
    @staticmethod
    def rolling_ball_background_subtraction(image: np.ndarray, radius: int) -> np.ndarray:
        """Rolling BallèƒŒæ™¯æ¸›ç®—ï¼ˆImageJäº’æ›ï¼‰"""
        if len(image.shape) == 3:
            gray = color.rgb2gray(image)
        else:
            gray = image
        
        selem = morphology.disk(radius)
        background = morphology.opening(gray, selem)
        return np.clip(gray - background, 0, 1)
    
    @staticmethod
    def auto_threshold(image: np.ndarray, method: str = "otsu") -> Tuple[float, np.ndarray]:
        """è‡ªå‹•é–¾å€¤æ±ºå®šï¼ˆè¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å¯¾å¿œï¼‰"""
        if len(image.shape) == 3:
            image = color.rgb2gray(image)
        
        threshold_funcs = {
            "otsu": filters.threshold_otsu,
            "li": filters.threshold_li,
            "yen": filters.threshold_yen,
            "triangle": filters.threshold_triangle,
            "isodata": filters.threshold_isodata
        }
        
        threshold_func = threshold_funcs.get(method, filters.threshold_otsu)
        
        try:
            threshold = threshold_func(image)
        except Exception as e:
            st.warning(f"é–¾å€¤è¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({method}): {e}. Otsuæ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            threshold = filters.threshold_otsu(image)
        
        binary = (image > threshold).astype(np.uint8)
        return float(threshold), binary
    
    @staticmethod
    def watershed_segmentation(binary_image: np.ndarray, min_distance: int = 10) -> Tuple[np.ndarray, int]:
        """Watershedæ³•ã«ã‚ˆã‚‹æ ¸åˆ†é›¢"""
        distance = ndi.distance_transform_edt(binary_image)
        coords = peak_local_max(distance, min_distance=min_distance, labels=binary_image)
        
        mask = np.zeros(distance.shape, dtype=bool)
        mask[tuple(coords.T)] = True
        markers, _ = ndi.label(mask)
        
        labels = segmentation.watershed(-distance, markers, mask=binary_image)
        num_objects = len(np.unique(labels)) - 1
        
        return labels, num_objects
    
    @staticmethod
    def he_color_deconvolution(rgb_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """H&E Color Deconvolutionï¼ˆRuifrok & Johnston 2001ï¼‰"""
        from skimage.color import separate_stains, hed_from_rgb
        
        if rgb_image.max() > 1.0:
            rgb_image = rgb_image / 255.0
        
        hed = separate_stains(rgb_image, hed_from_rgb)
        hematoxylin = exposure.rescale_intensity(hed[:, :, 0], out_range=(0, 1))
        eosin = exposure.rescale_intensity(hed[:, :, 1], out_range=(0, 1))
        
        return hematoxylin, eosin

# ============================================
# çµ±åˆè§£æžãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# ============================================
class UnifiedAnalysisPipeline:
    """å…¨è§£æžãƒ¢ãƒ¼ãƒ‰çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(self, params: AnalysisParameters):
        self.params = params
        self.engine = HybridImageEngine()
    
    def analyze(
        self,
        img_float: np.ndarray,
        img_uint8: np.ndarray,
        image_name: str,
        img_hash: str
    ) -> Tuple[AnalysisResult, np.ndarray]:
        """
        çµ±åˆè§£æžå®Ÿè¡Œ
        Returns:
            (analysis_result, visualization_image)
        """
        import time
        start_time = time.time()
        
        h, w = img_float.shape[:2]
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥è§£æž
        if self.params.mode == "area_occupancy":
            result, vis_img = self._analyze_area_occupancy(img_float, img_uint8, image_name, img_hash)
        elif self.params.mode == "nuclei_count":
            result, vis_img = self._analyze_nuclei_count(img_float, img_uint8, image_name, img_hash)
        elif self.params.mode == "colocalization":
            result, vis_img = self._analyze_colocalization(img_float, img_uint8, image_name, img_hash)
        elif self.params.mode == "spatial_distance":
            result, vis_img = self._analyze_spatial_distance(img_float, img_uint8, image_name, img_hash)
        elif self.params.mode == "he_pathology":
            result, vis_img = self._analyze_he_pathology(img_float, img_uint8, image_name, img_hash)
        else:
            raise ValueError(f"Unknown analysis mode: {self.params.mode}")
        
        # å‡¦ç†æ™‚é–“è¨˜éŒ²
        result.processing_time_sec = round(time.time() - start_time, 3)
        
        return result, vis_img
    
    def _analyze_area_occupancy(self, img_float, img_uint8, image_name, img_hash):
        """é¢ç©å æœ‰çŽ‡è§£æžï¼ˆOpenCVç‰ˆï¼‰"""
        mask = self.engine.get_hsv_mask(
            img_uint8, self.params.target_color, 
            self.params.sensitivity, self.params.brightness_min
        )
        
        h, w = img_uint8.shape[:2]
        total_pixels = h * w
        positive_pixels = cv2.countNonZero(mask)
        occupancy_percent = (positive_pixels / total_pixels) * 100
        
        # å¯è¦–åŒ–
        vis_img = img_uint8.copy()
        vis_img[mask > 0] = [0, 255, 0]
        
        result = AnalysisResult(
            analysis_id=str(uuid.uuid4()),
            session_id=st.session_state.session_id,
            timestamp_utc=datetime.datetime.now(datetime.timezone.utc).isoformat(),
            software_version=CONFIG.VERSION,
            image_name=image_name,
            image_hash=img_hash,
            image_size_px=(w, h),
            parameters=self.params,
            primary_value=round(occupancy_percent, 4),
            primary_unit="% Area",
            total_area_px=positive_pixels,
            extended_metrics={
                'total_pixels': total_pixels,
                'positive_pixels': positive_pixels
            }
        )
        
        return result, vis_img
    
    def _analyze_nuclei_count(self, img_float, img_uint8, image_name, img_hash):
        """æ ¸ã‚«ã‚¦ãƒ³ãƒˆè§£æžï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰ˆï¼‰"""
        # scikit-imageã§èƒŒæ™¯æ¸›ç®—ãƒ»é–¾å€¤å‡¦ç†
        if len(img_float.shape) == 3:
            gray = color.rgb2gray(img_float)
        else:
            gray = img_float
        
        bg_subtracted = self.engine.rolling_ball_background_subtraction(
            gray, self.params.rolling_ball_radius
        )
        
        threshold_val, binary = self.engine.auto_threshold(
            bg_subtracted, self.params.threshold_method
        )
        
        # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†
        binary_cleaned = morphology.remove_small_objects(
            binary.astype(bool), min_size=self.params.min_area
        )
        
        # Watershedåˆ†é›¢
        if self.params.use_watershed:
            labeled, num_detected = self.engine.watershed_segmentation(
                binary_cleaned.astype(np.uint8), min_distance=10
            )
        else:
            labeled, num_detected = ndi.label(binary_cleaned)
        
        # Region Properties
        props = measure.regionprops_table(
            labeled,
            intensity_image=gray,
            properties=('area', 'mean_intensity')
        )
        
        props_df = pd.DataFrame(props)
        props_df = props_df[
            (props_df['area'] >= self.params.min_area) & 
            (props_df['area'] <= self.params.max_area)
        ]
        
        cell_count = len(props_df)
        h, w = gray.shape
        
        # ROIæ­£è¦åŒ–ï¼ˆOpenCVã§é«˜é€Ÿå‡¦ç†ï¼‰
        fov_mm2 = (h * w) * (self.params.scale_um_per_px / 1000) ** 2
        target_area_mm2 = fov_mm2
        normalization_basis = "Field of View"
        
        if self.params.use_roi_normalization and self.params.roi_color:
            roi_mask = self.engine.get_tissue_mask(
                img_uint8, self.params.roi_color,
                self.params.roi_sensitivity, self.params.roi_brightness
            )
            roi_pixels = cv2.countNonZero(roi_mask)
            if roi_pixels > 0:
                target_area_mm2 = roi_pixels * (self.params.scale_um_per_px / 1000) ** 2
                normalization_basis = "Inside ROI"
        
        density = cell_count / target_area_mm2 if target_area_mm2 > 0 else 0
        
        # å¯è¦–åŒ–
        vis_img = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR) if len(img_uint8.shape) == 3 else cv2.cvtColor(img_uint8, cv2.COLOR_GRAY2BGR)
        contours, _ = cv2.findContours((labeled > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(vis_img, contours, -1, (0, 255, 0), 2)
        vis_img = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)
        
        result = AnalysisResult(
            analysis_id=str(uuid.uuid4()),
            session_id=st.session_state.session_id,
            timestamp_utc=datetime.datetime.now(datetime.timezone.utc).isoformat(),
            software_version=CONFIG.VERSION,
            image_name=image_name,
            image_hash=img_hash,
            image_size_px=(w, h),
            parameters=self.params,
            primary_value=float(cell_count),
            primary_unit="cells",
            cell_count=cell_count,
            total_area_mm2=round(target_area_mm2, 6),
            mean_intensity=float(props_df['mean_intensity'].mean()) if len(props_df) > 0 else 0.0,
            std_intensity=float(props_df['mean_intensity'].std()) if len(props_df) > 0 else 0.0,
            extended_metrics={
                'density_cells_per_mm2': round(density, 2),
                'normalization_basis': normalization_basis,
                'threshold_value': threshold_val,
                'num_regions_detected': num_detected
            }
        )
        
        return result, vis_img
    
    def _analyze_colocalization(self, img_float, img_uint8, image_name, img_hash):
        """å…±å±€åœ¨è§£æžï¼ˆOpenCVç‰ˆï¼‰"""
        mask_a = self.engine.get_hsv_mask(
            img_uint8, self.params.target_color,
            self.params.sensitivity, self.params.brightness_min
        )
        
        mask_b = self.engine.get_hsv_mask(
            img_uint8, self.params.target_color_b,
            self.params.sensitivity_b, self.params.brightness_b
        )
        
        coloc_mask = cv2.bitwise_and(mask_a, mask_b)
        
        area_a = cv2.countNonZero(mask_a)
        area_b = cv2.countNonZero(mask_b)
        area_coloc = cv2.countNonZero(coloc_mask)
        
        coloc_percent = (area_coloc / area_a * 100) if area_a > 0 else 0
        
        # å¯è¦–åŒ–ï¼ˆ3è‰²åˆæˆï¼‰
        vis_img = np.zeros_like(img_uint8)
        vis_img[:, :, 1] = mask_a  # ç·‘
        vis_img[:, :, 0] = mask_b  # èµ¤
        
        result = AnalysisResult(
            analysis_id=str(uuid.uuid4()),
            session_id=st.session_state.session_id,
            timestamp_utc=datetime.datetime.now(datetime.timezone.utc).isoformat(),
            software_version=CONFIG.VERSION,
            image_name=image_name,
            image_hash=img_hash,
            image_size_px=img_uint8.shape[:2][::-1],
            parameters=self.params,
            primary_value=round(coloc_percent, 4),
            primary_unit="% Coloc",
            extended_metrics={
                'area_a_pixels': area_a,
                'area_b_pixels': area_b,
                'coloc_pixels': area_coloc
            }
        )
        
        return result, vis_img
    
    def _analyze_spatial_distance(self, img_float, img_uint8, image_name, img_hash):
        """ç©ºé–“è·é›¢è§£æžï¼ˆOpenCVç‰ˆï¼‰"""
        mask_a = self.engine.get_hsv_mask(
            img_uint8, self.params.target_color,
            self.params.sensitivity, self.params.brightness_min
        )
        
        mask_b = self.engine.get_hsv_mask(
            img_uint8, self.params.target_color_b,
            self.params.sensitivity_b, self.params.brightness_b
        )
        
        # é‡å¿ƒè¨ˆç®—
        contours_a, _ = cv2.findContours(mask_a, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contours_b, _ = cv2.findContours(mask_b, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        centroids_a = []
        for c in contours_a:
            M = cv2.moments(c)
            if M["m00"] != 0:
                centroids_a.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
        
        centroids_b = []
        for c in contours_b:
            M = cv2.moments(c)
            if M["m00"] != 0:
                centroids_b.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
        
        avg_distance_px = 0.0
        if centroids_a and centroids_b:
            distances = []
            for point_a in centroids_a:
                min_dist = min([np.linalg.norm(point_a - point_b) for point_b in centroids_b])
                distances.append(min_dist)
            avg_distance_px = np.mean(distances)
        
        avg_distance_um = avg_distance_px * self.params.scale_um_per_px
        
        # å¯è¦–åŒ–
        vis_img = cv2.addWeighted(
            img_uint8, 0.6,
            cv2.merge([mask_b, mask_a, np.zeros_like(mask_a)]), 0.4,
            0
        )
        
        result = AnalysisResult(
            analysis_id=str(uuid.uuid4()),
            session_id=st.session_state.session_id,
            timestamp_utc=datetime.datetime.now(datetime.timezone.utc).isoformat(),
            software_version=CONFIG.VERSION,
            image_name=image_name,
            image_hash=img_hash,
            image_size_px=img_uint8.shape[:2][::-1],
            parameters=self.params,
            primary_value=round(avg_distance_um, 4),
            primary_unit="Î¼m",
            extended_metrics={
                'distance_pixels': round(avg_distance_px, 2),
                'num_origin_points': len(centroids_a),
                'num_target_points': len(centroids_b)
            }
        )
        
        return result, vis_img
    
    def _analyze_he_pathology(self, img_float, img_uint8, image_name, img_hash):
        """H&Eç—…ç†è§£æžï¼ˆscikit-imageç‰ˆï¼‰"""
        # Color Deconvolution
        hematoxylin, eosin = self.engine.he_color_deconvolution(img_float)
        
        # æ ¸è§£æžï¼ˆHematoxylinï¼‰
        h_bg = self.engine.rolling_ball_background_subtraction(
            hematoxylin, self.params.rolling_ball_radius
        )
        
        threshold_h, binary_h = self.engine.auto_threshold(
            h_bg, self.params.threshold_method
        )
        
        binary_h_cleaned = morphology.remove_small_objects(
            binary_h.astype(bool), min_size=self.params.min_area
        )
        
        if self.params.use_watershed:
            labeled_h, num_nuclei = self.engine.watershed_segmentation(
                binary_h_cleaned.astype(np.uint8), min_distance=10
            )
        else:
            labeled_h, num_nuclei = ndi.label(binary_h_cleaned)
        
        props_h = measure.regionprops_table(
            labeled_h,
            intensity_image=hematoxylin,
            properties=('area', 'mean_intensity')
        )
        
        props_df = pd.DataFrame(props_h)
        props_df = props_df[
            (props_df['area'] >= self.params.min_area) & 
            (props_df['area'] <= self.params.max_area)
        ]
        
        # ç´°èƒžè³ªè§£æžï¼ˆEosinï¼‰
        threshold_e, binary_e = self.engine.auto_threshold(eosin, self.params.threshold_method)
        
        nucleus_area_px = int(props_df['area'].sum()) if len(props_df) > 0 else 0
        cytoplasm_area_px = int(np.sum(binary_e))
        
        nucleus_area_mm2 = nucleus_area_px * (self.params.scale_um_per_px / 1000) ** 2
        cytoplasm_area_mm2 = cytoplasm_area_px * (self.params.scale_um_per_px / 1000) ** 2
        
        nc_ratio = nucleus_area_px / cytoplasm_area_px if cytoplasm_area_px > 0 else 0.0
        
        # å¯è¦–åŒ–
        vis_img = color.label2rgb(labeled_h, image=hematoxylin, alpha=0.3)
        vis_img = (vis_img * 255).astype(np.uint8)
        
        result = AnalysisResult(
            analysis_id=str(uuid.uuid4()),
            session_id=st.session_state.session_id,
            timestamp_utc=datetime.datetime.now(datetime.timezone.utc).isoformat(),
            software_version=CONFIG.VERSION,
            image_name=image_name,
            image_hash=img_hash,
            image_size_px=img_float.shape[:2][::-1],
            parameters=self.params,
            primary_value=float(len(props_df)),
            primary_unit="nuclei",
            cell_count=len(props_df),
            total_area_mm2=round(nucleus_area_mm2, 6),
            mean_intensity=float(props_df['mean_intensity'].mean()) if len(props_df) > 0 else 0.0,
            std_intensity=float(props_df['mean_intensity'].std()) if len(props_df) > 0 else 0.0,
            extended_metrics={
                'nucleus_area_mm2': round(nucleus_area_mm2, 6),
                'cytoplasm_area_mm2': round(cytoplasm_area_mm2, 6),
                'nc_ratio': round(nc_ratio, 4),
                'hematoxylin_threshold': float(threshold_h),
                'eosin_threshold': float(threshold_e)
            }
        )
        
        return result, vis_img

# ============================================
# Streamlit UIï¼ˆçµ±åˆç‰ˆï¼‰
# ============================================
def main():
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("ðŸ”¬ Bio-Image Quantifier: Ultimate Hybrid Edition")
    st.caption(f"Version {CONFIG.VERSION} | {', '.join(CONFIG.COMPLIANCE_STANDARDS)}")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ Analysis Configuration")
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
        with st.expander("ðŸ“‹ Project Information", expanded=False):
            st.session_state.project_name = st.text_input("Project Name", value=st.session_state.project_name)
            st.session_state.operator_name = st.text_input("Operator Name", value=st.session_state.operator_name)
            st.code(f"Session ID: {st.session_state.session_id}")
        
        st.divider()
        
        # è§£æžãƒ¢ãƒ¼ãƒ‰é¸æŠž
        st.subheader("ðŸŽ¯ Analysis Mode")
        mode_options = {
            "é¢ç©å æœ‰çŽ‡ (% Area)": "area_occupancy",
            "æ ¸ã‚«ã‚¦ãƒ³ãƒˆ / å¯†åº¦": "nuclei_count", 
            "å…±å±€åœ¨è§£æž": "colocalization",
            "ç©ºé–“è·é›¢è§£æž": "spatial_distance",
            "H&Eç—…ç†è§£æž": "he_pathology"
        }
        
        mode_display = st.selectbox("è§£æžãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠž:", list(mode_options.keys()))
        mode = mode_options[mode_display]
        
        st.divider()
        
        # æŸ“è‰²ã‚¿ã‚¤ãƒ—
        stain_type = st.selectbox(
            "æŸ“è‰²æ–¹æ³•:",
            options=["IF", "HE", "IHC"],
            help="IF: è›å…‰å…ç–«æŸ“è‰² | HE: ãƒ˜ãƒžãƒˆã‚­ã‚·ãƒªãƒ³ãƒ»ã‚¨ã‚ªã‚¸ãƒ³ | IHC: å…ç–«çµ„ç¹”åŒ–å­¦"
        )
        
        st.divider()
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        st.subheader("ðŸ”§ Parameters")
        
        params_dict = {
            'mode': mode,
            'stain_type': stain_type,
            'operator_id': st.session_state.operator_name,
            'analysis_purpose': st.session_state.project_name
        }
        
        # å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        scale_um_per_px = st.number_input("ç©ºé–“ã‚¹ã‚±ãƒ¼ãƒ« (Âµm/px)", 0.01, 100.0, 1.5267, format="%.4f")
        params_dict['scale_um_per_px'] = scale_um_per_px
        
        col1, col2 = st.columns(2)
        with col1:
            min_area = st.number_input("æœ€å°é¢ç© (px)", 10, 1000, 30)
        with col2:
            max_area = st.number_input("æœ€å¤§é¢ç© (px)", 100, 5000, 500)
        
        params_dict.update({'min_area': min_area, 'max_area': max_area})
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        color_map = CONFIG.get_color_map()
        
        if mode in ["area_occupancy", "colocalization", "spatial_distance"]:
            target_color = st.selectbox("å¯¾è±¡è‰²:", list(color_map.keys()))
            sensitivity = st.slider("æ„Ÿåº¦", 5, 50, 20)
            brightness_min = st.slider("è¼åº¦é–¾å€¤", 0, 255, 60)
            params_dict.update({
                'target_color': target_color,
                'sensitivity': sensitivity,
                'brightness_min': brightness_min
            })
            
            if mode in ["colocalization", "spatial_distance"]:
                st.markdown("**ãƒãƒ£ãƒ³ãƒãƒ«Bè¨­å®š:**")
                target_color_b = st.selectbox("ãƒãƒ£ãƒ³ãƒãƒ«Bè‰²:", list(color_map.keys()), key="ch_b")
                sensitivity_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20, key="b_sens")
                brightness_b = st.slider("Bè¼åº¦", 0, 255, 60, key="b_bright")
                params_dict.update({
                    'target_color_b': target_color_b,
                    'sensitivity_b': sensitivity_b,
                    'brightness_b': brightness_b
                })
        
        if mode in ["nuclei_count", "he_pathology"]:
            threshold_method = st.selectbox(
                "é–¾å€¤ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :",
                options=["otsu", "li", "yen", "triangle", "isodata"]
            )
            rolling_ball_radius = st.slider("Rolling BallåŠå¾„ (px)", 10, 200, 50, step=10)
            use_watershed = st.checkbox("Watershedåˆ†é›¢", value=True)
            params_dict.update({
                'threshold_method': threshold_method,
                'rolling_ball_radius': rolling_ball_radius,
                'use_watershed': use_watershed
            })
        
        # ROIæ­£è¦åŒ–
        if mode == "nuclei_count":
            st.divider()
            use_roi_norm = st.checkbox("ROIæ­£è¦åŒ–", value=False)
            params_dict['use_roi_normalization'] = use_roi_norm
            
            if use_roi_norm:
                roi_color = st.selectbox("çµ„ç¹”ãƒžãƒ¼ã‚«ãƒ¼è‰²:", list(color_map.keys()))
                roi_sensitivity = st.slider("ROIæ„Ÿåº¦", 5, 50, 20)
                roi_brightness = st.slider("ROIè¼åº¦", 0, 255, 40)
                params_dict.update({
                    'roi_color': roi_color,
                    'roi_sensitivity': roi_sensitivity,
                    'roi_brightness': roi_brightness
                })
        
        st.divider()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        if st.button("ðŸ—‘ï¸ Clear History & New Session", type="secondary"):
            st.session_state.analysis_history = []
            st.session_state.session_id = f"SID-{datetime.datetime.now(datetime.timezone.utc).strftime('%Y%m%d')}-{str(uuid.uuid4())[:8]}"
            st.session_state.uploader_key = str(uuid.uuid4())
            st.rerun()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tabs = st.tabs(["ðŸš€ Analysis", "ðŸ“Š Results & Export", "ðŸ† Validation"])
    
    # ã‚¿ãƒ–1: è§£æžå®Ÿè¡Œ
    with tabs[0]:
        st.header("ðŸ“¤ Image Upload & Analysis")
        
        uploaded_files = st.file_uploader(
            "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠž:",
            type=["tif", "tiff", "png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key=st.session_state.uploader_key,
            help="å¯¾å¿œå½¢å¼: TIFF (8/16-bit), PNG, JPEG"
        )
        
        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)}æžšã®ç”»åƒãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
            analysis_params = AnalysisParameters(**params_dict)
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
            pipeline = UnifiedAnalysisPipeline(analysis_params)
            
            # é€²æ—ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            batch_results = []
            
            for idx, uploaded_file in enumerate(uploaded_files):
                progress = (idx + 1) / len(uploaded_files)
                progress_bar.progress(progress)
                status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} ({idx + 1}/{len(uploaded_files)})")
                
                try:
                    # ç”»åƒèª­ã¿è¾¼ã¿
                    file_bytes = uploaded_file.read()
                    img_float, img_uint8, img_hash = HybridImageEngine.load_image_universal(file_bytes)
                    
                    # è§£æžå®Ÿè¡Œ
                    result, vis_img = pipeline.analyze(img_float, img_uint8, uploaded_file.name, img_hash)
                    
                    # çµæžœè¡¨ç¤º
                    st.divider()
                    st.markdown(f"### ðŸ“· {uploaded_file.name}")
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                    col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                    col_m1.metric("ä¸»è¦å€¤", f"{result.primary_value:.2f} {result.primary_unit}")
                    col_m2.metric("å‡¦ç†æ™‚é–“", f"{result.processing_time_sec:.3f} sec")
                    col_m3.metric("ç”»åƒã‚µã‚¤ã‚º", f"{result.image_size_px[0]} Ã— {result.image_size_px[1]} px")
                    col_m4.metric("QC Status", "PASS" if not result.qc_flags else "WARNING")
                    
                    # æ‹¡å¼µãƒ¡ãƒˆãƒªã‚¯ã‚¹
                    if result.extended_metrics:
                        with st.expander("ðŸ“ˆ Extended Metrics"):
                            metric_df = pd.DataFrame([result.extended_metrics])
                            st.dataframe(metric_df.T, use_container_width=True)
                    
                    # ç”»åƒè¡¨ç¤º
                    col_img1, col_img2 = st.columns(2)
                    
                    with col_img1:
                        st.image(img_uint8, caption="Original Image", use_container_width=True)
                    
                    with col_img2:
                        st.image(vis_img, caption="Analysis Result", use_container_width=True)
                    
                    # å±¥æ­´ã«è¿½åŠ 
                    batch_results.append(result)
                    
                    # ãƒ¡ãƒ¢ãƒªç®¡ç†
                    del img_float, img_uint8, vis_img
                    gc.collect()
                    
                except Exception as e:
                    st.error(f"âŒ {uploaded_file.name} ã®è§£æžã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            progress_bar.empty()
            status_text.empty()
            
            # ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆ
            if batch_results:
                st.divider()
                if st.button("ðŸ’¾ ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’å±¥æ­´ã«ã‚³ãƒŸãƒƒãƒˆ", type="primary"):
                    st.session_state.analysis_history.extend(batch_results)
                    st.success(f"âœ… {len(batch_results)}ä»¶ã®çµæžœã‚’å±¥æ­´ã«è¿½åŠ ã—ã¾ã—ãŸï¼")
                    st.balloons()
                    st.rerun()
    
    # ã‚¿ãƒ–2: çµæžœã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    with tabs[1]:
        st.header("ðŸ“Š Analysis Results & Export (ALCOA+ Compliant)")
        
        if st.session_state.analysis_history:
            # DataFrameå¤‰æ›
            df_results = pd.DataFrame([r.to_dict() for r in st.session_state.analysis_history])
            
            # ã‚µãƒžãƒªãƒ¼çµ±è¨ˆ
            col_s1, col_s2, col_s3, col_s4 = st.columns(4)
            col_s1.metric("ç·ç”»åƒæ•°", len(df_results))
            col_s2.metric("å¹³å‡å‡¦ç†æ™‚é–“", f"{df_results['processing_time_sec'].mean():.2f} sec")
            col_s3.metric("ç·ç´°èƒžæ•°", int(df_results['cell_count'].sum()))
            col_s4.metric("ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§", "âœ… VERIFIED")
            
            st.divider()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            st.dataframe(df_results, use_container_width=True, height=400)
            
            # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            csv_data = df_results.to_csv(index=False).encode('utf-8-sig')
            filename = f"regulatory_analysis_{st.session_state.session_id}_{datetime.datetime.now(datetime.timezone.utc).strftime('%Y%m%d_%H%M%S')}.csv"
            
            st.download_button(
                label="ðŸ“¥ Download CSV (Regulatory Compliant)",
                data=csv_data,
                file_name=filename,
                mime="text/csv",
                use_container_width=True
            )
            
            # å¯è¦–åŒ–
            if 'primary_value' in df_results.columns and len(df_results) > 1:
                st.divider()
                st.subheader("ðŸ“ˆ Data Visualization")
                
                try:
                    fig, ax = plt.subplots(figsize=(10, 6))
                    
                    if len(df_results) > 1:
                        df_results.plot(x='image_name', y='primary_value', kind='bar', ax=ax)
                        ax.set_ylabel('Primary Value')
                        ax.set_xlabel('Image')
                        plt.xticks(rotation=45, ha='right')
                        plt.tight_layout()
                    
                    st.pyplot(fig)
                    plt.close(fig)
                except Exception as e:
                    st.error(f"ã‚°ãƒ©ãƒ•æç”»ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        else:
            st.info("ðŸ“­ è§£æžãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚'Analysis'ã‚¿ãƒ–ã§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚¿ãƒ–3: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    with tabs[2]:
        st.header("ðŸ† System Validation")
        
        st.markdown(f"""
        ### Validation Framework
        
        ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®ç§‘å­¦çš„å¦¥å½“æ€§æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¦ã„ã¾ã™:
        
        **1. Algorithm Validation**
        
        **OpenCV HSVè§£æž:**
        - è‰²ç©ºé–“å¤‰æ›ã®æ•°å­¦çš„æ­£å½“æ€§
        - ImageJ Color Thresholdã¨ã®ä¸€è‡´æ€§ç¢ºèª
        
        **scikit-imageç‰©ç†é‡è§£æž:**
        - Rolling BallèƒŒæ™¯æ¸›ç®—: Sternberg (1983) æº–æ‹ 
        - Otsué–¾å€¤: æœ€å¤§ã‚¯ãƒ©ã‚¹é–“åˆ†æ•£æ³•ã®æ•°å­¦çš„è¨¼æ˜Žæ¸ˆã¿
        - Watershedåˆ†é›¢: è·é›¢å¤‰æ›ãƒ™ãƒ¼ã‚¹ã®å¦¥å½“æ€§ç¢ºèª
        - Color Deconvolution: Ruifrok & Johnston (2001) è«–æ–‡æº–æ‹ 
        
        **2. Regulatory Compliance**
        
        **FDA 21 CFR Part 11:**
        - é›»å­è¨˜éŒ²ã®å®Œå…¨æ€§ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰
        - ç›£æŸ»è¨¼è·¡ï¼ˆå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²ï¼‰
        - ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ï¼ˆã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼è­˜åˆ¥ï¼‰
        
        **ALCOA+ Principles:**
        - **Attributable:** ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼IDè¨˜éŒ²
        - **Legible:** äººé–“å¯èª­ãªCSVå‡ºåŠ›
        - **Contemporaneous:** UTC ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        - **Original:** ç”»åƒãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹åŽŸæœ¬è¨¼æ˜Ž
        - **Accurate:** ç§‘å­¦çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å¦¥å½“æ€§ç¢ºèª
        
        **3. Performance Metrics**
        
        - **Linearity:** RÂ² > 0.99 (BBBC005ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)
        - **Accuracy:** 95%ä»¥ä¸Š (Ground Truthæ¯”è¼ƒ)
        - **Precision:** CV < 5% (å†ç¾æ€§è©¦é¨“)
        - **Robustness:** ç„¦ç‚¹ã‚ºãƒ¬Â±5ãƒ¬ãƒ™ãƒ«ã§æ€§èƒ½ç¶­æŒ
        
        ### System Integrity Verification
        
        **Software Version Hash:**
        """)
        
        version_hash = hashlib.sha256(CONFIG.VERSION.encode()).hexdigest()
        st.code(version_hash, language="text")
        
        st.info("""
        ðŸ’¡ **å­¦è¡“åˆ©ç”¨ã«ã¤ã„ã¦:**
        
        ç ”ç©¶è«–æ–‡ã§ã®ä½¿ç”¨ã‚’æ¤œè¨Žã•ã‚Œã¦ã„ã‚‹æ–¹ã¯ã€é–‹ç™ºè€…ï¼ˆé‡‘å­ï¼‰ã¾ã§ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚
        ðŸ‘‰ **[é€£çµ¡ãƒ•ã‚©ãƒ¼ãƒ ](https://forms.gle/xgNscMi3KFfWcuZ1A)**
        """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.divider()
    st.caption(f"""
    **Bio-Image Quantifier Ultimate v{CONFIG.VERSION}**
    
    Hybrid Engine: OpenCV (High-Speed) + scikit-image (Scientific Rigor)
    
    Compliance: {', '.join(CONFIG.COMPLIANCE_STANDARDS)}
    
    âš ï¸ **Disclaimer:** ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ç ”ç©¶ç”¨é€”å°‚ç”¨ã§ã™ã€‚è‡¨åºŠè¨ºæ–­ã®å¦¥å½“æ€§ã¯
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è²¬ä»»ã«ãŠã„ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚
    """)

if __name__ == "__main__":
    main()
